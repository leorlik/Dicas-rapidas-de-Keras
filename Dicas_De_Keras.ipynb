{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Observação geral: Esse guia rápido supõe que a abordagem utilizada é sequencial e não pela Keras API_\n",
    "\n",
    "## Plot de gráfico\n",
    "Forma de chamada: \n",
    "\n",
    "~~~python\n",
    "graph_plots(argumento)\n",
    "~~~\n",
    "\n",
    "Isso irá te dar um gráfico do treino e da validação. Dá pra usar a função para qualquer métrica, mas o gráfico exibirá com o nome de acc.\n",
    "\n",
    "*Nota: Não usar para conjuntos apenas de treino e sem validação*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [10,7]\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "def graph_plots(history):\n",
    "    plt.clf()\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n",
    "\n",
    "As callbacks são especificações para alguns comportamentos do modelo, como:\n",
    "\n",
    "* A ReduceLROnPlateau, que diminui a taxa de aprendizado conforme a perda não minimiza, para assim caminhar em espaço menor e não ficar presa em um mínimo local;\n",
    "* A ModelCheckpoint, que salva num arquivo .h5 (Formato que o Keras sabe ler) a melhor versão do seu modelo;\n",
    "* E a EarlyStopping, que, ao contrário da ReduceLROnPlateau, para o treinamento quando ele parecer inútil.\n",
    "\n",
    "_Observação: **NÃO é uma boa ideia utilizar a ReduceLR sem o par do ModelCheckpoint**_\n",
    "\n",
    "A callbacks_list_v1 contém o par __ReduceLR__ e __ModelCheckpoint__, salvando a melhor versão do modelo e o otimizando para não se prender em mínimos locais de acordo com a _Validation Loss_.\n",
    "\n",
    "A callbacks_list_v2 é a __EarlyStopping__, que parará o treinamento caso a perda não diminua em um determinado numero de épocas (default pela função: 5).\n",
    "\n",
    "Para a callbacks_list_v1, de um nome (string) ao seu modelo (argumento name) e opcionalmente um caminho de arquivo(string), se por exemplo você quiser salvar seu modelo em uma pasta diferente da atual. O modelo se salvará no local especificado.\n",
    "\n",
    "A callbacks_list_v2 tem o argumento opcional patience, que especifica a tolerância em épocas caso você queira que ela demore mais ou menos de 5 épocas da métrica monitorada para parar.\n",
    "\n",
    "Ambas funções possuem o argumento opcional monitor, caso queira monitorar outra métrica se não a _Validation Loss_.\n",
    "\n",
    "_Observação: A compilação só aceita essas callbacks em forma de lista_.\n",
    "\n",
    "Forma de chamada:\n",
    "\n",
    "~~~python\n",
    "callbacks_list = callbacks_list_v1('MeuModelo')\n",
    "##ou\n",
    "callbacks_list = callbacks_list_v2()\n",
    "~~~\n",
    "\n",
    "Forma de compilação do modelo:\n",
    "\n",
    "~~~python\n",
    "history = model.fit(x=x,\n",
    "                    y=y,\n",
    "                    #...especificaçoes de fit diversas\n",
    "                    callbacks=callbacks_list)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "import os\n",
    "\n",
    "def callbacks_list_v1(name, file_path='',monitor = 'val_loss'):\n",
    "    callbacks_list = [\n",
    "                    callbacks.ReduceLROnPlateau(\n",
    "                        monitor=monitor,\n",
    "                        factor=0.1,\n",
    "                        patience=10,\n",
    "                        ),\n",
    "                    callbacks.ModelCheckpoint(\n",
    "                        filepath=os.path.join(file_path,name+'.h5'),\n",
    "                        monitor=monitor,\n",
    "                        save_best_only=True,\n",
    "                        mode=\"auto\",\n",
    "                        save_weights_only=False,\n",
    "                        ),\n",
    "                    ]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callbacks_list_v2(patience=5,monitor ='val_loss'):\n",
    "    callbacks_list = [\n",
    "        callbacks.EarlyStopping(\n",
    "                    monitor=monitor,\n",
    "                    min_delta=0,\n",
    "                    patience=patience,\n",
    "                    verbose=0,\n",
    "                    mode=\"auto\",\n",
    "                    baseline=None,\n",
    "                    restore_best_weights=True,\n",
    "        )\n",
    "                     ]\n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendação de Otimizadores\n",
    "\n",
    "* Nos meus testes, o SGD não foi tão bom;\n",
    "* O Nadam apresenta algumas vezes melhores resultados;\n",
    "* O RMSProp é o mais usado, e traz sempre bons resultados;\n",
    "\n",
    "Adapte o learning_rate. Aumente-o se quiser que o modelo aprenda mais rápido, ou diminua-o se achar que ele está indo rápido demais. Recomendo testar com 1e-3 e 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "NadamOpt = optimizers.Nadam(lr=1e-4)\n",
    "RMSOpt = optimizers.RMSprop(lr=1e-4)\n",
    "SGDOpt = optimizers.SGD(lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recomendação de ativações\n",
    "\n",
    "A LeakyRelu é implementada como camada e não como uma própria ativação, então se quiser usá-la passe pelas camadas sem ativação e coloque a camada layers.LeakyRelu() após cada camada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "\n",
    "SwishActivation = tf.nn.swish\n",
    "model.add(layers.LeakyRelu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dica Final\n",
    "\n",
    "Aplicar normalização no seu modelo pode melhorá-lo. Se quiser, após cada camada convolucional, adicione a camada BatchNormalization da seguinte forma:\n",
    " \n",
    "~~~python\n",
    "model.add(layers.BatchNormalization())\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
